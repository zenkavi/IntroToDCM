<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,IE=9,chrome=1"><meta name="generator" content="MATLAB 2020b"><title>rDCM connectivity matrix pruning</title><style type="text/css">.rtcContent { padding: 30px; } .S0 { margin: 3px 10px 5px 4px; padding: 0px; line-height: 28.8px; min-height: 0px; white-space: pre-wrap; color: rgb(213, 80, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 24px; font-weight: 400; text-align: left;  }
.S1 { margin: 2px 10px 9px 4px; padding: 0px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(0, 0, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 400; text-align: left;  }
.S2 { margin: 20px 10px 5px 4px; padding: 0px; line-height: 20px; min-height: 0px; white-space: pre-wrap; color: rgb(60, 60, 60); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 20px; font-weight: 700; text-align: left;  }
.S3 { margin: 15px 10px 5px 4px; padding: 0px; line-height: 18px; min-height: 0px; white-space: pre-wrap; color: rgb(60, 60, 60); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 17px; font-weight: 700; text-align: left;  }
.S4 { margin: 10px 0px 20px; padding-left: 0px; font-family: Helvetica, Arial, sans-serif; font-size: 14px;  }
.S5 { margin-left: 56px; line-height: 21px; min-height: 0px; text-align: left; white-space: pre-wrap;  }</style></head><body><div class = rtcContent><h1  class = 'S0'><span>rDCM connectivity matrix pruning</span></h1><div  class = 'S1'><span>In this notebook we'll describe the procedure first described in Frässle et al. (2018) that prunes a fully connected network to estimate only certain connectivity parameters.</span></div><div  class = 'S1'><span>Based on Eq. 7 in Frässle et al. 2018 pruning happens with the addition of a feature selector Z matrix placed between the design matrix X (that contains the other nodes activity and convolved inputs in the frequency domain) and the parameters vector </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">θ</span><span>. Z is a diagonal matrix with binary indicators that effectively "selects" columns from X. If the diagonal in Z corresponding to a column in X is 0 then no parameter is estimated for that feature (or </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">θ</span><span>=0). Different from the ridge regression optimization is run over not just the connectivity parameters </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">θ</span><span> and measurement noise </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">τ</span><span> but also the feature selector matrix Z.</span></div><div  class = 'S1'><span>Z is determined by its diagonal </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">ζ</span><span>'s which come from a binomial distribution with probability </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">p</span><span>. This </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">p</span><span> is what is updated in each variational iteration to update Z.</span></div><div  class = 'S1'><span style=' font-family: monospace;'>tapas_rdcm_sparse.m</span><span> is provided with a prior </span><span mathmlencoding="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;inline&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;italic&quot;&gt;p&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB8AAAAoCAYAAAAG0SEsAAAC8ElEQVRYR+3WW4hXVRQG8J/RhZKioouUF0qQ7KULlHTTtAwCfUhCRSm6Uj0VVEI+FVF0IbGnsgtGT1qUT9JVSyOkKIpKSpSSiFIJJAopo5Qv9hmO2zOjfx2ch/7rZWb22Xt9a31rfWvNKCNoo0YQWx98RNjv096n/Ygy0G+4I0p3A3Yg2vP9LPyLX8qjk3AOtmH74UTdBT4RD+IK5PfjsQBr8Azm4+gC+iEW4udDCWKozBPAU/gHV+EJPI9PMQeP4RisKn/3jD8U+L1Yim+wEXfhtxbCJ7i0BHcCdveKPhT4m7gBuzAZP1bOn8Pd5Sw9sHW4wI/CrzgFz+K+DsdvtOhOE/4+XOCXlNrG38X4osNxSnF+UUEU0bbRuBqTkKb8EntqH4PR/hAex+bioH6XRvsDx5YmvKd14TKEldvxLZ7En7i1SHbg6mDgkdWMIq0HOrK+Ay/ib1xUGjLXzsXneBRLyrsTsQmvYHHbVxd4dL0Tx+EarK3Ak3UYmYBH8HDre7JchHH4qXX+Mm7E2YWx/z51gc/Eu/gLJxfK2viRXPSemqcfGonFV4ZNKE73t+0WLMdt5eeg4E30G3B55SRT7x3swOwW3bl2ejn/GFdW767Fe3UZuzJPzZLR65jbcjKlOFiPm0pp2hgXFlWsxqwKvFHPPj5r8NNK9DnP0kg901QZNpnzy4ru95MNpmJdR9CJI5JMmT4ojdxJezJdWep9Bi5AuvUHfNel1VaG5xVpvY3rq8wzhjOOX8O85lud+Qu4E6F2WofEhjpKc0YlXb1yXemVfaZlDf596dRaQgcbx2cYizHVg+yA7IJsw2zB/WhPTbeU8+llLB4saHMvGo9aUoIMlsZWINknqIHt1848uzs7PJY6Z3z2ankXqWUwNcsow+hr3F+m4oDPgJ+JzPKMzCyE2Et4C1mrvdp4vIqPSpPejPfxdO0o4BmnGYe1hZ6ed3TLyalIIF/VC6W5c6B/IHvNuqf7ffCe6Bquy/9f2vcC36SRKSdmohUAAAAASUVORK5CYII=" width="15.5" height="20" /></span><span> that is used in a binomial distribution to determine the initial Z matrix. It then loops through each region and estimates parameters for both connectivity and task involvement for each region depending on the "feature selectivity" vector determined by p0 for that region (detailed below).</span></div><div  class = 'S1'><span>In their simulations Frässle et al. found that the recovered parameters especially for connectivity depended on how close the prior p0 was to the true sparseness of the simulation. So in their estimations </span><span style=' font-family: monospace;'>tapas_rdcm_sparse.m</span><span> is run for a number of prior values determined in </span><span style=' font-family: monospace;'>tapas_rdcm_estimate.m</span><span>.</span></div><div  class = 'S1'><span>Here I provide a brief overview of the procedures in each step and then simulate some data to explore the effects of the prior on the estimated connectivity matrix.</span></div><h2  class = 'S2'><span>Order of operation</span></h2><div  class = 'S1'><span style=' font-family: monospace;'>tapas_rdcm_estimate.m</span><span> --&gt; </span><span style=' font-family: monospace;'>tapas_rdcm_sparse.m</span><span> --&gt; </span><span style=' font-family: monospace;'>tapas_rdcm_get_prior_all.m</span><span> --&gt; </span><span style=' font-family: monospace;'>tapas_rdcm_spm_dcm_fmri_priors.m </span></div><h3  class = 'S3'><span>tapas_rdcm_estimate.m</span></h3><ul  class = 'S4'><li  class = 'S5'><span>For the sparse method iterates over (19) p0_temp values ranging from 0.05 to 0.95 and calls </span><span style=' font-family: monospace;'>tapas_rdcm_sparse.m</span><span> for each p0_temp value.</span></li><li  class = 'S5'><span>Saves output for each p0_temp value in </span><span style=' font-family: monospace;'>output_all</span></li><li  class = 'S5'><span>Selects the cell from </span><span style=' font-family: monospace;'>output_all</span><span> that has the highest Free Energy (empirical Bayes)</span></li><li  class = 'S5'><span>So what does p0_temp change in </span><span style=' font-family: monospace;'>tapas_rdcm_sparse.m</span><span>?</span></li></ul><h3  class = 'S3'><span>tapas_rdcm_sparse.m</span></h3><ul  class = 'S4'><li  class = 'S5'><span>Loops through each node/region</span></li><li  class = 'S5'><span>100 iterations of reinitializations for each node, up to 500 convergence rounds</span></li><li  class = 'S5'><span>p0_temp determines p0 vector ("informativeness of feature", "sparsity hyperparameter") in each of these iterations</span></li><li  class = 'S5'><span>            p0 is the prior probability for the Bernoulli distribution that sets the binary indicators (zetas </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">ζ</span><span>) for the existance of a connection</span></li><li  class = 'S5'><span>E.g. for our simulations for node 1 it is [1 p0_temp p0_temp 1]. Its length is determined by the number of parameters that will be estimated for that regions. In this case the first three values are the connectivity values (A(1,:)) and the last value is the input effect (C(1)). The first value is the self-connection, second and third are connections </span><span style=' font-weight: bold;'>incoming</span><span> </span><span style=' font-weight: bold;'>from </span><span>(verified in Frässle et al. 2018, p 508) other regions to this region.</span></li><li  class = 'S5'><span>Select estimates with the highest Free Energy from all iterations for each region (</span><span style=' font-weight: bold;'>for the given p0_temp value</span><span>)</span></li><li  class = 'S5'><span>            For each node there are 100 iterations/initilizations that have up to 500 convergence rounds</span></li><li  class = 'S5'><span>            So should there be a lot or little variability in the parameter estimates depending on iteration? Little to none.</span></li><li  class = 'S5'><span>Posterior's for p (z_r variable) are stored in output.Ip.A</span></li></ul><h3  class = 'S3'><span>tapars_rdcm_get_prior_all.m</span></h3><ul  class = 'S4'><li  class = 'S5'><span>resets pE.A from </span><span style=' font-family: monospace;'>tapas_rdcm_spm_dcm_fmri_priors.m</span><span> to 0's except for inhibitory self connections</span></li><li  class = 'S5'><span>m0 = [pE.A pE.B pE.C]; i.e. all prior expectations</span></li><li  class = 'S5'><span style=' font-weight: bold;'>inverts</span><span> all values in pC resulting from </span><span style=' font-family: monospace;'>tapas_rdcm_spm_dcm_fmri_priors.m </span><span>(l0 is </span><span mathmlencoding="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;inline&quot;&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mrow&gt;&lt;mi&gt;Σ&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msubsup&gt;&lt;/mrow&gt;&lt;/math&gt;" style="vertical-align:-8px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAsCAYAAAAjFjtnAAADWElEQVRoQ+3YWch1UxgH8N+HRCgy5IJIkihCRKaEZCgS4cLQR5kKF6bIHBcopUylZJ4yZMwQJfMQN7iTKbMMoeSC/lpbu9P7nbPO2Xu/zlvvutvnPOt5/v/1rGdaKyzxtWKJ47dM4P/24LIHFsEDW2ETvLmQrXn2wBa4GCfhclxTQ2A9vI61ZzzZ53DmjHvb2zbGbtgZVxYiVQSi5Djc19J218h389ca2LAYORHr4zEc2QOBRsXeeGVaAtl8NS4qWv7EfnhjDLCt8Q5enhcCiY1HcUQB/S12xRdjSOS+7jIvBIJzXbyGHQro97EX/lgFiYA/D8fOwxVqMGyJt5GgynoYx+DvHkGOUzVzDLSVRsmLWLP8eFnJDDUcnmjtmyR/Kj4bEeqFQHSejNuL8pz+0XhkEiLchGSrmnUFvhqKQPTegHOKgd9LPHxQg6yDTG8eCIbV8TQOwi/YEx92AFeztVcCMZgMk8IWEsn5Q6+0EXfgWlywkLFpeqGdSlU8A3cPjHwdnF1iL81c6tAlSKvyedt2LYHN8BZuxVUDg59KfQ2BNHiv4j2srNCemvF9hVwvIpMIJAU+hdVwKP6qsJq+ffcKuV5EJhG4DXuUlPlrhcVkpuvLngrx7iLjCJyPs8ppfllhKqee4I4Hjh+R3xYHlGB8AT9X6KsSWRWBVNoH8RN+mKApOjZFYiUrFTUTVFZqx/3l6l2IZLKbS5f7bhXCCuOjIrkyL2GtGQ2c0EqzN+IobIPfir5zy6yxHb6Z0cZ/20Y9kFP8BBt1UJw4yFi6Ab7GPTilpW/zkssv7SMlTwriDjychlvKUH7niKJP+fdRLYN7pzUkgXSiqdoHlna8DTR1JZ6Kx5urNRORIQk8jsPLKDoasGkKD8H2+Ggm5GXTkASSCPIYsBDIh8pMsW/pr2bmMCSBB8r4mfqQPqq9nsHBSCb6eGb0JZC67B+3txmA0no/PyKYLJV0nUzVqagN6YHD8CROL11sm0PS63fYsevpDUkgjwAB+Wx57Wuwpq3ItUmrct08Ewi2TFSpxgnk5lEs3/uXNNrp+sTAkB5oDjePXclG95ag3ad4pKZBnOigxSDQHFTue7zw40RUUwgsFoEpIE0nukxguvPqX3rZA/2f6XQal7wH/gGP9ZQtYqSHVAAAAABJRU5ErkJggg==" width="24" height="22" /></span><span>)</span></li><li  class = 'S5'><span>l0 = [pC.A pC.B pC.C]; i.e. all prior covariances</span></li><li  class = 'S5'><span>sets noise shape and rate parameters priors to 2 and 1 respectively </span></li></ul><h3  class = 'S3'><span>tapas_rdcm_spm_dcm_fmri_priors.m </span></h3><ul  class = 'S4'><li  class = 'S5'><span>pE describes prior expected values and pC prior covariances</span></li><li  class = 'S5'><span style=' font-weight: bold;'>for A: prior on self-connectivity is inhibitory (diag of pE.A &lt; 0) and narrow (diag of pC.A is small)</span></li><li  class = 'S5'><span style=' font-weight: bold;'>for other connections in A the priors are closer to 0 and wide</span></li><li  class = 'S5'><span>pE and pC are set to 0 and 1 respectively for B, C, D matrices</span></li></ul></div>
<br>
<!-- 
##### SOURCE BEGIN #####
%% rDCM connectivity matrix pruning
% In this notebook we'll describe the procedure first described in Frässle et 
% al. (2018) that prunes a fully connected network to estimate only certain connectivity 
% parameters.
% 
% Based on Eq. 7 in Frässle et al. 2018 pruning happens with the addition of 
% a feature selector Z matrix placed between the design matrix X (that contains 
% the other nodes activity and convolved inputs in the frequency domain) and the 
% parameters vector $\theta$. Z is a diagonal matrix with binary indicators that 
% effectively "selects" columns from X. If the diagonal in Z corresponding to 
% a column in X is 0 then no parameter is estimated for that feature (or $\theta$=0). 
% Different from the ridge regression optimization is run over not just the connectivity 
% parameters $\theta$ and measurement noise $\tau$ but also the feature selector 
% matrix Z.
% 
% Z is determined by its diagonal $\zeta$'s which come from a binomial distribution 
% with probability $p$. This $p$ is what is updated in each variational iteration 
% to update Z.
% 
% |tapas_rdcm_sparse.m| is provided with a prior $p_0$ that is used in a binomial 
% distribution to determine the initial Z matrix. It then loops through each region 
% and estimates parameters for both connectivity and task involvement for each 
% region depending on the "feature selectivity" vector determined by p0 for that 
% region (detailed below).
% 
% In their simulations Frässle et al. found that the recovered parameters especially 
% for connectivity depended on how close the prior p0 was to the true sparseness 
% of the simulation. So in their estimations |tapas_rdcm_sparse.m| is run for 
% a number of prior values determined in |tapas_rdcm_estimate.m|.
% 
% Here I provide a brief overview of the procedures in each step and then simulate 
% some data to explore the effects of the prior on the estimated connectivity 
% matrix.
%% Order of operation
% |tapas_rdcm_estimate.m| REPLACE_WITH_DASH_DASH> |tapas_rdcm_sparse.m| REPLACE_WITH_DASH_DASH> |tapas_rdcm_get_prior_all.m| 
% REPLACE_WITH_DASH_DASH> |tapas_rdcm_spm_dcm_fmri_priors.m| 
% tapas_rdcm_estimate.m
%% 
% * For the sparse method iterates over (19) p0_temp values ranging from 0.05 
% to 0.95 and calls |tapas_rdcm_sparse.m| for each p0_temp value.
% * Saves output for each p0_temp value in |output_all|
% * Selects the cell from |output_all| that has the highest Free Energy (empirical 
% Bayes)
% * So what does p0_temp change in |tapas_rdcm_sparse.m|?
% tapas_rdcm_sparse.m
%% 
% * Loops through each node/region
% * 100 iterations of reinitializations for each node, up to 500 convergence 
% rounds
% * p0_temp determines p0 vector ("informativeness of feature", "sparsity hyperparameter") 
% in each of these iterations
% * p0 is the prior probability for the Bernoulli distribution that sets the 
% binary indicators (zetas $\zeta$) for the existance of a connection
% * E.g. for our simulations for node 1 it is [1 p0_temp p0_temp 1]. Its length 
% is determined by the number of parameters that will be estimated for that regions. 
% In this case the first three values are the connectivity values (A(1,:)) and 
% the last value is the input effect (C(1)). The first value is the self-connection, 
% second and third are connections *incoming* *from* (verified in Frässle et al. 
% 2018, p 508) other regions to this region.
% * Select estimates with the highest Free Energy from all iterations for each 
% region (*for the given p0_temp value*)
% * For each node there are 100 iterations/initilizations that have up to 500 
% convergence rounds
% * So should there be a lot or little variability in the parameter estimates 
% depending on iteration? Little to none.
% * Posterior's for p (z_r variable) are stored in output.Ip.A
% tapars_rdcm_get_prior_all.m
%% 
% * resets pE.A from |tapas_rdcm_spm_dcm_fmri_priors.m| to 0's except for inhibitory 
% self connections
% * m0 = [pE.A pE.B pE.C]; i.e. all prior expectations
% * *inverts* all values in pC resulting from |tapas_rdcm_spm_dcm_fmri_priors.m| 
% (l0 is $\Sigma_0^{-1}$)
% * l0 = [pC.A pC.B pC.C]; i.e. all prior covariances
% * sets noise shape and rate parameters priors to 2 and 1 respectively 
% tapas_rdcm_spm_dcm_fmri_priors.m 
%% 
% * pE describes prior expected values and pC prior covariances
% * *for A: prior on self-connectivity is inhibitory (diag of pE.A < 0) and 
% narrow (diag of pC.A is small)*
% * *for other connections in A the priors are closer to 0 and wide*
% * pE and pC are set to 0 and 1 respectively for B, C, D matrices
##### SOURCE END #####
--></body></html>